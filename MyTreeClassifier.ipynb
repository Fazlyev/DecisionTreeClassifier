{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Моя реализация алгоритма \"Дерево решений\""
      ],
      "metadata": {
        "id": "kCKNQWi_0z7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данной работе я хотел бы самостоятельно написать один из базовых алгоритмов машинного обучения - Decision tree, и сравнить его с встроенной в sklearn моделью по точности и скорости. Здесь представлена вариация для классификации, и для создания датасета я использую функцию make_classification из sklearn."
      ],
      "metadata": {
        "id": "RQIH-t7d0_jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "jQp5-d9MzzTF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Процесс обучения строится следующим образом:\n",
        "\n",
        "1) Модель принимает на вход фичи и таргет\n",
        "\n",
        "2) Создается словарь, в котором для каждой фичи будут храниться ее потенциальные разделители. В качестве разделителей в базовом случае используются разделители для отсортированных уникальных значений. В случае использования гистограмного метода, если число разделителей гистограммы меньше исходного, записываем их как разделители для фичи\n",
        "\n",
        "3) Строим дерево, для каждого узла отбирая лучший разделитель либо с помощью прироста информации, либо с помощью неопределенности Джини\n",
        "\n",
        "4) Параллельно ведем подсчет листьев и подсчет глубины для каждой ветви, чтобы не превысить заданные ограничения."
      ],
      "metadata": {
        "id": "H5Gc3PDo1rv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Для лучшей структуризации кода, пропишем нужные в процессе обучения функции до создания самого класса:"
      ],
      "metadata": {
        "id": "i6jgSIXi3Jbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateGini(arr):\n",
        "  left_gini = 1 - (np.sum(arr[0]==0)/len(arr[0]))**2 - (np.sum(arr[0]==1)/len(arr[0]))**2\n",
        "  right_gini = 1 - (np.sum(arr[1]==0)/len(arr[1]))**2 - (np.sum(arr[1]==1)/len(arr[1]))**2\n",
        "  gini = (len(arr[0])*left_gini + len(arr[1])*right_gini)/(len(arr[0])+len(arr[1]))\n",
        "  return gini\n",
        "\n",
        "\n",
        "def calculateEntropy(y): # считаем энтропию таргета\n",
        "  values, counts = np.unique(y, return_counts=True)\n",
        "  probabilities = counts/np.sum(counts)\n",
        "  entropy = -np.sum(probabilities*np.log2(probabilities))\n",
        "  return entropy\n",
        "\n",
        "\n",
        "def calculateIG(arr, s): # получаем на вход список массивов, на которые разбили изначальный, и начальную энтропию\n",
        "  lens = [len(arr[i]) for i in range(len(arr))]\n",
        "  weights = np.array(lens)/np.sum(lens)\n",
        "  return s - np.sum([weights[i]*calculateEntropy(arr[i]) for i in range(len(arr))])\n",
        "\n",
        "\n",
        "class TreeNode:\n",
        "  def __init__(self, X=None, y=None, feature=None, splitter=None):\n",
        "    self.y = y\n",
        "    self.X = X\n",
        "    self.feature = feature\n",
        "    self.splitter = splitter\n",
        "    self.val = None\n",
        "    self.left = None\n",
        "    self.right = None"
      ],
      "metadata": {
        "id": "3zfEGVIvzxSB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реализуем класс, включив в него функцию для отбора лучшего разделителя, поскольку в процессе используется атрибут класса, и так будет проще вести его изменение прямо во время работы. Класс поддерживает следующие модификации:\n",
        "- Гистограмный метод создания разделителей (будет полезен, когда мы используем данный алгоритм при создании градиентного бустинга)\n",
        "- выбор критерия для отбора лучшего разделителя (Энтропия или неопределенность Джини)\n",
        "- предсказание вероятностей классов\n",
        "- отрисовка дерева в понятном виде для отладки кода"
      ],
      "metadata": {
        "id": "5oUXDOwU3q1A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xHsdq3hXzgkJ"
      },
      "outputs": [],
      "source": [
        "class MyTreeClf:\n",
        "  def __init__(self, max_depth = 5, min_samples_split = 2, max_leafs = 20, bins=None, criterion = 'entropy'):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.max_leaves = max_leafs\n",
        "    self.bins = bins\n",
        "    self.criterion = criterion\n",
        "    self.fi = {}\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'class MyTreeClf: max_depth = {self.max_depth}, min_samples_split = {self.min_samples_split}, max_leaves = {self.max_leaves}'\n",
        "\n",
        "  def get_best_split(self, X, y):\n",
        "    features = X.columns\n",
        "    best_feature = features[0]\n",
        "    best_splitter = None\n",
        "    best_IG = 0\n",
        "    best_gini = 1\n",
        "    s = calculateEntropy(y)\n",
        "\n",
        "    for name in features:\n",
        "      feature = X[name]\n",
        "      #splitters = np.unique((np.unique(feature)[1:]+np.unique(feature)[:-1])/2)\n",
        "      splitters = self.splitters[name]\n",
        "\n",
        "      #if self.bins:\n",
        "        #if len(splitters)>self.bins-1:\n",
        "          #splitters = self.histogram[name]\n",
        "\n",
        "      if len(splitters)>0:\n",
        "        for splitter in splitters:\n",
        "          arr = [y[feature<=splitter], y[feature>splitter]]\n",
        "          if len(arr[0])==0 or len(arr[1])==0:\n",
        "            continue\n",
        "          if self.criterion == 'entropy':\n",
        "            IG = calculateIG(arr, s)\n",
        "            if IG>best_IG:\n",
        "              best_IG = IG\n",
        "              best_splitter = splitter\n",
        "              best_feature = name\n",
        "          else:\n",
        "            gini = calculateGini(arr)\n",
        "            if gini<best_gini:\n",
        "              best_splitter = splitter\n",
        "              best_feature = name\n",
        "              best_gini = gini\n",
        "\n",
        "    if self.criterion == 'entropy':\n",
        "      return best_feature, best_splitter, best_IG\n",
        "    else:\n",
        "      return best_feature, best_splitter, best_gini\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.y = y\n",
        "    self.root = TreeNode(X, y)\n",
        "    self.root.val = np.mean(y)\n",
        "    self.histogram = pd.DataFrame()\n",
        "    self.splitters = {}\n",
        "    for name in X.columns:\n",
        "      self.fi[name] = 0\n",
        "      self.splitters[name] = (np.unique(X[name])[1:]+np.unique(X[name])[:-1])/2\n",
        "\n",
        "    if self.bins:\n",
        "      #self.histogram = pd.DataFrame(columns = X.columns)\n",
        "      for name in X.columns:\n",
        "        if len(self.splitters[name])>self.bins-1:\n",
        "          self.splitters[name] = np.histogram(X[name], bins=self.bins)[1][1:-1]\n",
        "        #self.histogram[name] = np.histogram(X[name], bins=self.bins)[1][1:-1]\n",
        "\n",
        "    def inorder(root, depth=1):\n",
        "      if (self.leaves+1<=self.max_leaves or self.leaves<2) and depth<=self.max_depth and root and len(root.y)>=self.min_samples_split and np.mean(root.y)!=0 and np.mean(root.y)!=1:\n",
        "        # если условия позволяют, создаем левого и правого соседей и обходим их\n",
        "        root.val = np.mean(root.y)\n",
        "        best_feature, best_splitter = self.get_best_split(root.X, root.y)[:-1]\n",
        "\n",
        "        if not best_splitter:\n",
        "          root.left = None\n",
        "          root.right = None\n",
        "          root.val = np.mean(root.y)\n",
        "          return None\n",
        "\n",
        "        root.feature = best_feature\n",
        "        root.splitter = best_splitter\n",
        "\n",
        "        left_X = root.X[root.X[best_feature]<=best_splitter]\n",
        "        right_X = root.X[root.X[best_feature]>best_splitter]\n",
        "        left_y = root.y[left_X.index]\n",
        "        right_y = root.y[right_X.index]\n",
        "\n",
        "        root.left = TreeNode(left_X, left_y)\n",
        "        root.right = TreeNode(right_X, right_y)\n",
        "\n",
        "        if len(root.left.y)>0 and len(root.right.y)>0:\n",
        "          if self.criterion == 'entropy':\n",
        "            self.fi[best_feature]+=len(root.y)/len(self.y)*(calculateEntropy(root.y) - len(left_y)/len(root.y)*calculateEntropy(left_y) - len(right_y)/len(root.y)*calculateEntropy(right_y))\n",
        "          else:\n",
        "            left_gini = 1 - (np.sum(left_y==0)/len(left_y))**2 - (np.sum(left_y==1)/len(left_y))**2\n",
        "            right_gini = 1 - (np.sum(right_y==0)/len(right_y))**2 - (np.sum(right_y==1)/len(right_y))**2\n",
        "            gini = 1 - (np.sum(root.y==0)/len(root.y))**2 - (np.sum(root.y==1)/len(root.y))**2\n",
        "            self.fi[best_feature]+=len(root.y)/len(self.y)*(gini - len(left_y)/len(root.y)*left_gini - len(right_y)/len(root.y)*right_gini)\n",
        "\n",
        "          self.leaves+=1\n",
        "          inorder(root.left, depth+1)\n",
        "          inorder(root.right, depth+1)\n",
        "        else:\n",
        "          root.left = None\n",
        "          root.right = None\n",
        "          root.val = np.mean(root.y)\n",
        "\n",
        "      else:\n",
        "        # превращаем в лист\n",
        "        root.val = np.mean(root.y)\n",
        "\n",
        "    self.leaves = 1\n",
        "    inorder(self.root)\n",
        "    self.leafs_cnt = self.leaves\n",
        "\n",
        "\n",
        "  def print_tree(self):\n",
        "    def traversal(root, depth=0):\n",
        "      if root:\n",
        "        if root.left or root.right:\n",
        "          print('    '*depth, f'{root.feature} > {root.splitter}')\n",
        "          traversal(root.left, depth+1)\n",
        "          traversal(root.right, depth+1)\n",
        "        else:\n",
        "          print('    '*depth, f'leaf val = {root.val}')\n",
        "    traversal(self.root)\n",
        "\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    self.pred_proba = pd.Series(index = X.index)\n",
        "    def searchLeaf(X, root):\n",
        "      if not root.feature:\n",
        "        self.pred_proba[X.index] = root.val\n",
        "      else:\n",
        "        searchLeaf(X[X[root.feature]<=root.splitter], root.left)\n",
        "        searchLeaf(X[X[root.feature]>root.splitter], root.right)\n",
        "\n",
        "    searchLeaf(X, self.root)\n",
        "    return self.pred_proba\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    self.pred_y = pd.Series(index = X.index)\n",
        "    def searchLeaf(X, root):\n",
        "      if not root.feature:\n",
        "        self.pred_y[X.index] = (root.val>=0.5)\n",
        "      else:\n",
        "        searchLeaf(X[X[root.feature]<=root.splitter], root.left)\n",
        "        searchLeaf(X[X[root.feature]>root.splitter], root.right)\n",
        "\n",
        "    searchLeaf(X, self.root)\n",
        "    return self.pred_y.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создадим датасет для тестирования, обучим модель и изобразим дерево"
      ],
      "metadata": {
        "id": "B-EW1njX4h5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples=1000, n_features=8, n_informative=5, random_state=42)\n",
        "X = pd.DataFrame(X).round(2)\n",
        "y = pd.Series(y)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "test = X.sample(200, random_state=42)\n",
        "\n",
        "tree = MyTreeClf(\n",
        "    max_depth=10,\n",
        "    min_samples_split=2,\n",
        "    max_leafs=30,\n",
        "    criterion = 'gini'\n",
        ")\n",
        "\n",
        "tree.fit(X, y)\n",
        "tree.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Hlj2vK0GFp",
        "outputId": "7cd19fde-92b0-4ba9-b85a-5e0ed86347c7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " col_7 > -0.2\n",
            "     col_1 > -1.6150000000000002\n",
            "         col_4 > -0.11499999999999999\n",
            "             col_0 > -0.175\n",
            "                 col_1 > -2.865\n",
            "                     col_1 > -2.875\n",
            "                         leaf val = 0.0\n",
            "                         leaf val = 1.0\n",
            "                     leaf val = 0.0\n",
            "                 col_6 > 0.875\n",
            "                     col_2 > 0.945\n",
            "                         leaf val = 1.0\n",
            "                         leaf val = 0.0\n",
            "                     leaf val = 0.0\n",
            "             col_2 > -0.495\n",
            "                 col_4 > 0.46499999999999997\n",
            "                     leaf val = 0.0\n",
            "                     leaf val = 1.0\n",
            "                 leaf val = 1.0\n",
            "         col_1 > -0.685\n",
            "             col_4 > -0.015\n",
            "                 col_7 > -0.69\n",
            "                     col_2 > -1.105\n",
            "                         col_0 > -1.315\n",
            "                             leaf val = 1.0\n",
            "                             leaf val = 0.0\n",
            "                         leaf val = 1.0\n",
            "                     col_0 > -1.73\n",
            "                         leaf val = 1.0\n",
            "                         col_0 > 0.765\n",
            "                             leaf val = 0.0\n",
            "                             leaf val = 1.0\n",
            "                 col_1 > -0.735\n",
            "                     leaf val = 1.0\n",
            "                     col_0 > -1.1150000000000002\n",
            "                         leaf val = 1.0\n",
            "                         leaf val = 0.0\n",
            "             col_3 > 2.215\n",
            "                 col_2 > -1.625\n",
            "                     col_2 > -1.755\n",
            "                         leaf val = 1.0\n",
            "                         leaf val = 0.0\n",
            "                     leaf val = 1.0\n",
            "                 leaf val = 0.0\n",
            "     col_6 > -0.20500000000000002\n",
            "         col_4 > -1.7650000000000001\n",
            "             leaf val = 0.0\n",
            "             col_7 > 0.885\n",
            "                 col_0 > 0.795\n",
            "                     col_3 > 2.145\n",
            "                         col_1 > 0.42\n",
            "                             leaf val = 0.0\n",
            "                             leaf val = 1.0\n",
            "                         col_4 > 1.1749999999999998\n",
            "                             leaf val = 0.84\n",
            "                             leaf val = 0.3333333333333333\n",
            "                     leaf val = 1.0\n",
            "                 leaf val = 0.8782051282051282\n",
            "         leaf val = 0.0982367758186398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим встроенную модель"
      ],
      "metadata": {
        "id": "BHp0zwWl6QQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sk_model = DecisionTreeClassifier(max_depth=10, max_leaf_nodes=30)\n",
        "sk_model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "X-ZmS43m0oeC",
        "outputId": "645f2b86-78df-4c82-9374-fbd9ed9d76de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=10, max_leaf_nodes=30)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, max_leaf_nodes=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, max_leaf_nodes=30)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним точность их предсказаний на том же датасете, на котором модели были обучены"
      ],
      "metadata": {
        "id": "qxQjifk46S_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(tree.predict(X) == y).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJxN-8T15U9x",
        "outputId": "b788b70c-bc8f-4a54-83e6-003fd9d61811"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-c2342d6423f9>:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  self.pred_y[X.index] = (root.val>=0.5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "932"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(sk_model.predict(X)==y).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC1bqGHI5blI",
        "outputId": "de7a6300-7036-4d07-8a8b-4394c3e410df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "971"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(tree.predict(X)==sk_model.predict(X)).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SWlNviH6bLw",
        "outputId": "f47b8b2f-16f6-4f20-ced5-cde90937137b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-c2342d6423f9>:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  self.pred_y[X.index] = (root.val>=0.5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "933"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy of our model = {accuracy_score(y, tree.predict(X))} and sklearn model = {accuracy_score(y, sk_model.predict(X))}')\n",
        "print(f'Precision of our model = {precision_score(y, tree.predict(X))} and sklearn model = {precision_score(y, sk_model.predict(X))}')\n",
        "print(f'Recall of our model = {recall_score(y, tree.predict(X))} and sklearn model = {recall_score(y, sk_model.predict(X))}')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdqgLEmO6ggL",
        "outputId": "9d014bf4-b7ea-43ed-c589-992b495972c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of our model = 0.932 and sklearn model = 0.971\n",
            "Precision of our model = 0.9520833333333333 and sklearn model = 0.9701789264413518\n",
            "Recall of our model = 0.9103585657370518 and sklearn model = 0.9721115537848606\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-c2342d6423f9>:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  self.pred_y[X.index] = (root.val>=0.5)\n",
            "<ipython-input-28-c2342d6423f9>:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  self.pred_y[X.index] = (root.val>=0.5)\n",
            "<ipython-input-28-c2342d6423f9>:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  self.pred_y[X.index] = (root.val>=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как мы видим, модель дает результаты, по точности сопоставимые встроенной в sklearn, хотя и уступает ей в скорости обучения. Исходя из этого я делаю вывод, что реализация вполне успешна."
      ],
      "metadata": {
        "id": "-bCTR7Zn8TeZ"
      }
    }
  ]
}